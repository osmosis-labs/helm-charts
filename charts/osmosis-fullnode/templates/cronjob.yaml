{{- if .Values.sentinel.enabled }}
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel
  namespace: {{ .Values.namespace }}
  labels:
{{ include "osmosis-fullnode.labels" . | indent 4 }}
    app.kubernetes.io/component: monitor
spec:
  schedule: "{{ .Values.sentinel.schedule }}"
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
{{- with .Values.sentinel.tolerations }}
{{- if . }}
          tolerations:
{{ toYaml . | indent 10 }}
{{- else }}
{{- with $.Values.statefulset.tolerations }}
          tolerations:
{{ toYaml . | indent 10 }}
{{- end }}
{{- end }}
{{- end }}
          serviceAccountName: {{ include "osmosis-fullnode.serviceAccountName" . }}
          affinity:
            podAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                  - key: statefulset.kubernetes.io/pod-name
                    operator: In
                    values:
                    - {{ include "osmosis-fullnode.fullname" . }}-0
                topologyKey: kubernetes.io/hostname
          containers:
          - name: directory-monitor
            image: {{ .Values.images.sentinel.repository }}:{{ .Values.images.sentinel.tag }}
            imagePullPolicy: {{ .Values.images.sentinel.pullPolicy }}
{{- if .Values.sentinel.resources }}
            resources:
{{- if .Values.sentinel.resources.requests }}
              requests:
{{ toYaml .Values.sentinel.resources.requests | indent 16 }}
{{- end }}
{{- if .Values.sentinel.resources.limits }}
              limits:
{{ toYaml .Values.sentinel.resources.limits | indent 16 }}
{{- end }}
{{- end }}
            env:
            - name: MAX_DIR_SIZE_GB
              valueFrom:
                configMapKeyRef:
                  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel-config
                  key: max-dir-size-gb
            - name: MONITOR_PATH
              valueFrom:
                configMapKeyRef:
                  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel-config
                  key: monitor-path
            - name: ARGOCD_APPLICATION
              valueFrom:
                configMapKeyRef:
                  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel-config
                  key: argocd-app
            - name: MAX_NODE_RESTART_COUNT
              valueFrom:
                configMapKeyRef:
                  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel-config
                  key: max-node-restart-count
            - name: ARGOCD_ENABLED
              valueFrom:
                configMapKeyRef:
                  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel-config
                  key: argocd-enabled
            - name: ARGOCD_SERVER
              valueFrom:
                configMapKeyRef:
                  name: {{ include "osmosis-fullnode.fullname" . }}-sentinel-config
                  key: argocd-server
            command:
            - bash
            - -c
            - |
              set -euo pipefail
              
              # Function to cleanup folders
              cleanup_folders() {
                local hostname=$1
                local namespace=$2
                local monitor_path=$3
                
                echo "üóëÔ∏è Starting folder cleanup..."
                
                # Delete the directories
                kubectl exec ${hostname} -n ${namespace} -- rm -rf ${monitor_path}/data
                kubectl exec ${hostname} -n ${namespace} -- rm -rf ${monitor_path}/wasm
                kubectl exec ${hostname} -n ${namespace} -- rm -rf ${monitor_path}/ibc_08-wasm
                
                # Verify data directory was deleted successfully 
                if kubectl exec ${hostname} -n ${namespace} -- bash -c "[ ! -d ${monitor_path}/data ]"; then
                  echo "‚úÖ Data directory deleted successfully"
                  return 0
                else
                  echo "‚ùå Failed to delete data directory"
                  return 1
                fi
              }

              # Function to check if ArgoCD is available
              check_argocd_available() {
                if [ "${ARGOCD_ENABLED:-true}" != "true" ]; then
                  echo "üì¥ ArgoCD integration is disabled via configuration"
                  return 1
                fi
                
                # Check if ArgoCD namespace exists
                if ! kubectl get namespace argocd >/dev/null 2>&1; then
                  echo "‚ö†Ô∏è ArgoCD namespace not found, skipping ArgoCD operations"
                  return 1
                fi
                
                # Check if the ArgoCD application exists
                if ! kubectl get application "$ARGOCD_APPLICATION" -n argocd >/dev/null 2>&1; then
                  echo "‚ö†Ô∏è ArgoCD application '$ARGOCD_APPLICATION' not found, skipping ArgoCD operations"
                  return 1
                fi
                
                echo "‚úÖ ArgoCD is available and configured"
                return 0
              }

              # Function to pause ArgoCD auto-sync using kubectl
              pause_argocd_sync() {
                if check_argocd_available; then
                  echo "‚è∏Ô∏è Pausing ArgoCD auto-sync for application: $ARGOCD_APPLICATION"
                  # Remove the syncPolicy to disable automated sync
                  if kubectl patch application "$ARGOCD_APPLICATION" -n argocd --type='merge' -p='{"spec":{"syncPolicy":null}}'; then
                    echo "‚úÖ ArgoCD auto-sync paused successfully"
                    return 0
                  else
                    echo "‚ùå Failed to pause ArgoCD auto-sync, continuing without ArgoCD management"
                    return 1
                  fi
                else
                  echo "‚ÑπÔ∏è Skipping ArgoCD pause operation"
                  return 1
                fi
              }

              # Function to resume ArgoCD auto-sync using kubectl
              resume_argocd_sync() {
                if check_argocd_available; then
                  echo "‚ñ∂Ô∏è Resuming ArgoCD auto-sync for application: $ARGOCD_APPLICATION"
                  # Set syncPolicy to automated
                  if kubectl patch application "$ARGOCD_APPLICATION" -n argocd --type='merge' -p='{"spec":{"syncPolicy":{"automated":{"prune":true,"selfHeal":true}}}}'; then
                    echo "‚úÖ ArgoCD auto-sync resumed successfully"
                  else
                    echo "‚ö†Ô∏è Failed to resume ArgoCD auto-sync, but cleanup completed"
                  fi
                else
                  echo "‚ÑπÔ∏è Skipping ArgoCD resume operation"
                fi
              }

              # Function to handle StatefulSet scaling and cleanup
              handle_cleanup() {
                local namespace=$1
                local osmosis_app=$2
                local osmosis_pod=$3
                
                # Track if we paused ArgoCD to know if we should resume it
                local argocd_was_paused=false
                
                # Pause ArgoCD auto-sync (if available)
                if pause_argocd_sync; then
                  argocd_was_paused=true
                fi
                
                # Scale down the StatefulSet to 0 replicas
                echo "üìâ Scaling down StatefulSet $osmosis_app to 0 replicas"
                kubectl scale statefulset $osmosis_app -n $namespace --replicas=0
                
                # Wait for the pod to terminate
                echo "‚è≥ Waiting for pod $osmosis_pod to terminate..."
                kubectl wait --for=delete pod/$osmosis_pod -n $namespace --timeout=600s

                if kubectl get pod $osmosis_pod -n $namespace &>/dev/null; then
                  echo "‚ùå Pod $osmosis_pod is still running after timeout"
                  # Try to resume ArgoCD if we paused it
                  if [ "$argocd_was_paused" = true ]; then
                    resume_argocd_sync
                  fi
                  exit 1
                fi
                
                echo "‚úÖ Pod $osmosis_pod successfully terminated"
                
                # Cleanup folders
                cleanup_folders $(hostname) $namespace $MONITOR_PATH
                
                # Scale the StatefulSet back to 1 replica
                echo "üìà Scaling StatefulSet $osmosis_app back to 1 replica"
                kubectl scale statefulset $osmosis_app -n $namespace --replicas=1
                
                # Resume ArgoCD auto-sync (if we paused it)
                if [ "$argocd_was_paused" = true ]; then
                  resume_argocd_sync
                fi
                
                echo "üîÑ Cleanup completed successfully"
              }

              # Install required packages quietly
              apt-get update -qq && apt-get install -y -qq coreutils bc curl gpg > /dev/null 2>&1
              
              # Install kubectl
              curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
              echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list
              apt-get update -qq && apt-get install -y -qq kubectl > /dev/null 2>&1
              echo "‚úÖ kubectl installed"
              
              # Get pod info
              NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
              echo "üîç Namespace: $NAMESPACE"
              
              # Get current hostname
              CURRENT_HOSTNAME=$(hostname)
              echo "üîç Hostname: $CURRENT_HOSTNAME"
              
              # Extract pod type and number from hostname
              # Expected format: {fullname}-{type}-{number}-sentinel-{cronJobId}-{podId}
              # Example: fullnodes-stage-osmosis-fullnode-node-0-sentinel-29224300-mktf4
              FULLNAME="{{ include "osmosis-fullnode.fullname" . }}"
              
              # Extract type (node or seed) - look for pattern after fullname
              if echo "$CURRENT_HOSTNAME" | grep -q "${FULLNAME}-node-"; then
                POD_TYPE="node"
                # Extract node number
                NODE_NUMBER=$(echo "$CURRENT_HOSTNAME" | sed "s/^${FULLNAME}-node-\([0-9]*\)-sentinel-.*$/\1/")
              elif echo "$CURRENT_HOSTNAME" | grep -q "${FULLNAME}-seed-"; then
                POD_TYPE="seed"
                # Extract seed number  
                NODE_NUMBER=$(echo "$CURRENT_HOSTNAME" | sed "s/^${FULLNAME}-seed-\([0-9]*\)-sentinel-.*$/\1/")
              else
                POD_TYPE="unknown"
                NODE_NUMBER="unknown"
              fi
              
              echo "üîç Pod Type: $POD_TYPE"
              echo "üîç Node Number: $NODE_NUMBER"
              
              OSMOSIS_APP="{{ include "osmosis-fullnode.fullname" . }}"
              OSMOSIS_POD="{{ include "osmosis-fullnode.fullname" . }}-0"
              echo "üîç Osmosis App: $OSMOSIS_APP"
              echo "üîç Osmosis Pod: $OSMOSIS_POD"

              # Display ArgoCD configuration status
              echo "üîç ArgoCD Integration: ${ARGOCD_ENABLED:-true}"
              if [ "${ARGOCD_ENABLED:-true}" = "true" ]; then
                echo "üîç ArgoCD Application: $ARGOCD_APPLICATION"
                check_argocd_available || echo "‚ö†Ô∏è ArgoCD not available in this environment"
              else
                echo "üì¥ ArgoCD integration is disabled"
              fi

              # Check if pod exists and get its status
              if ! kubectl get pod $OSMOSIS_POD -n $NAMESPACE &>/dev/null; then
                echo "‚ùå Pod $OSMOSIS_POD not found"
                exit 1
              fi

              # Check for CrashLoopBackOff status - handle case where pod is running
              POD_STATUS=$(kubectl get pod $OSMOSIS_POD -n $NAMESPACE -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}' 2>/dev/null)
              if [ -z "$POD_STATUS" ]; then
                # Pod is not in waiting state, check if it's running
                POD_PHASE=$(kubectl get pod $OSMOSIS_POD -n $NAMESPACE -o jsonpath='{.status.phase}' 2>/dev/null)
                POD_STATUS="${POD_PHASE:-Unknown}"
              fi
              
              RESTART_COUNT=$(kubectl get pod $OSMOSIS_POD -n $NAMESPACE -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")

              # Check directory size
              TOTAL_SIZE=$(kubectl exec $(hostname) -n $NAMESPACE -- du -sb $MONITOR_PATH 2>/dev/null | awk '{print $1}' || echo 0)
              SIZE_THRESHOLD=$(echo "${MAX_DIR_SIZE_GB:-100} * 1024 * 1024 * 1024" | bc) # Convert GB to bytes
              
              # Convert sizes to MB for display
              TOTAL_SIZE_MB=$(echo "scale=0; $TOTAL_SIZE / 1024 / 1024" | bc)
              THRESHOLD_MB=$(echo "scale=0; $SIZE_THRESHOLD / 1024 / 1024" | bc)
              
              echo "üìä Total size: ${TOTAL_SIZE_MB}MB"
              echo "üìä Threshold: ${THRESHOLD_MB}MB"
              echo "üìä Pod Status: $POD_STATUS"
              echo "üìä Restart Count: $RESTART_COUNT"

              # Check if cleanup is needed - properly quote variables and handle empty values
              MAX_RESTART_COUNT="${MAX_NODE_RESTART_COUNT:-10}"
              CURRENT_RESTART_COUNT="${RESTART_COUNT:-0}"
              
              if [ "$POD_STATUS" = "CrashLoopBackOff" ] || [ "$CURRENT_RESTART_COUNT" -gt "$MAX_RESTART_COUNT" ]; then
                echo "‚ö†Ô∏è Pod $OSMOSIS_POD is in CrashLoopBackOff state or has too many restarts ($CURRENT_RESTART_COUNT > $MAX_RESTART_COUNT)"
                handle_cleanup $NAMESPACE $OSMOSIS_APP $OSMOSIS_POD
              elif [ "$TOTAL_SIZE" -gt "$SIZE_THRESHOLD" ]; then
                echo "‚ö†Ô∏è Directory size (${TOTAL_SIZE_MB}MB) exceeds threshold (${THRESHOLD_MB}MB)"
                handle_cleanup $NAMESPACE $OSMOSIS_APP $OSMOSIS_POD
              else
                echo "‚úÖ Pod $OSMOSIS_POD is running normally and directory size is within limits"
              fi

            volumeMounts:
            - name: osmosis-data
              mountPath: /osmosis/.osmosisd
              readOnly: false
          volumes:
          - name: osmosis-data
            hostPath:
              path: {{ .Values.storage.hostPath }}
              type: Directory
          restartPolicy: Never
{{- end }} 
